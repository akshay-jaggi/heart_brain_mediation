{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reduction_joint_cca.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U_ipsjW9gUlD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cross_decomposition import CCA\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def project(data_matrix, latent_matrix):\n",
        "  latent_unit = latent_matrix / np.linalg.norm(latent_matrix)\n",
        "  proj_scores = np.matmul(data_matrix.T,latent_unit)\n",
        "  data_projected = np.outer(latent_unit, proj_scores.T)\n",
        "  return data_projected \n",
        "\n",
        "def evr_(data_matrix, latent_matrix):\n",
        "  data_projected = project(data_matrix, latent_matrix)\n",
        "  data_orth = data_matrix - data_projected\n",
        "  evr = 1 - sum(np.var(data_orth,axis=0)) / sum(np.var(data_matrix,axis=0))\n",
        "  return evr\n",
        "\n",
        "def evr_orth(dataset, latents):\n",
        "  evrs = np.apply_along_axis(lambda x: evr_(dataset, x), 0, latents)\n",
        "  return evrs, sum(evrs)"
      ],
      "metadata": {
        "id": "cWPTpfj2_Atj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "heart = pd.read_csv('heart.nozscore.csv').to_numpy()\n",
        "brain = pd.read_csv('brain.nozscore.csv').to_numpy()"
      ],
      "metadata": {
        "id": "_nkHWIRtgbs0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run Cross Validation to Assess Number and Stability of Components"
      ],
      "metadata": {
        "id": "upSSte3Fa2f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i = 0 \n",
        "ncomp = 10\n",
        "nsplit = 10\n",
        "cca = CCA(n_components=ncomp, scale = False)\n",
        "heart_evrs = np.zeros((nsplit,ncomp))\n",
        "brain_evrs = np.zeros((nsplit,ncomp))\n",
        "cors = np.zeros((nsplit,ncomp))\n",
        "for train_index, test_index in KFold(n_splits=10).split(heart):\n",
        "    heart_train, heart_test = heart[train_index], heart[test_index]\n",
        "    brain_train, brain_test = brain[train_index], brain[test_index]\n",
        "    heart_scaler = StandardScaler().fit(heart_train)\n",
        "    brain_scaler = StandardScaler().fit(brain_train)\n",
        "    heart_train_transformed = heart_scaler.transform(heart_train)\n",
        "    brain_train_transformed = brain_scaler.transform(brain_train)\n",
        "    heart_test_transformed = heart_scaler.transform(heart_test)\n",
        "    brain_test_transformed = brain_scaler.transform(brain_test)\n",
        "    cca.fit_transform(heart_train_transformed, brain_train_transformed)\n",
        "    heart_test_scores, brain_test_scores = cca.transform(heart_test_transformed, brain_test_transformed)\n",
        "    heart_evrs[i,:] = evr_orth(heart_test_transformed, heart_test_scores)[0]\n",
        "    brain_evrs[i,:] = evr_orth(brain_test_transformed, brain_test_scores)[0]\n",
        "    cors[i,:] = np.diag(np.corrcoef(heart_test_scores, brain_test_scores, rowvar=False),10)\n",
        "    i+=1"
      ],
      "metadata": {
        "id": "0TnnSy0rVeZT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(heart_evrs).to_csv('heart.evrs.crossval.csv')\n",
        "pd.DataFrame(brain_evrs).to_csv('brain.evrs.crossval.csv')\n",
        "pd.DataFrame(cors).to_csv('heart.brain.cors.crossval.csv')"
      ],
      "metadata": {
        "id": "ynQbs_A_Hu5I"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Run CCA on All Data "
      ],
      "metadata": {
        "id": "RcirgLi3bF3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cca = CCA(n_components=10, scale = True)\n",
        "heart_cc, brain_cc = cca.fit_transform(heart, brain)"
      ],
      "metadata": {
        "id": "3IARSkpJbI83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(cca.x_weights_,index=heart.columns).to_csv('heart_weights.csv')\n",
        "pd.DataFrame(cca.y_weights_,index=brain.columns).to_csv('brain_weights.csv')\n",
        "pd.DataFrame(cca.x_loadings_,index=heart.columns).to_csv('heart_loadings.csv')\n",
        "pd.DataFrame(cca.y_loadings_,index=brain.columns).to_csv('brain_loadings.csv')\n",
        "pd.DataFrame(cca.x_rotations_,index=heart.columns).to_csv('heart_rotations.csv')\n",
        "pd.DataFrame(cca.y_rotations_,index=brain.columns).to_csv('brain_rotations.csv')\n",
        "pd.DataFrame(heart_cc).to_csv('heart_ccs.csv')\n",
        "pd.DataFrame(brain_cc).to_csv('brain_ccs.csv')"
      ],
      "metadata": {
        "id": "FMB_QSLQq3-U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}